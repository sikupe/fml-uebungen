{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base classes\n",
    "\n",
    "class Node:\n",
    "    pass\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "\n",
    "    def find_leaf(self, x) -> Node:\n",
    "        node = self.root\n",
    "        while hasattr(node, \"feature\"):\n",
    "            j = node.feature\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bbox(data) -> (np.ndarray, np.ndarray):\n",
    "    return np.min(data, axis=0).copy(), np.max(data, axis=0).copy()\n",
    "\n",
    "\n",
    "class DensityTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DensityTree, self).__init__()\n",
    "\n",
    "    def train(self, data, prior, n_min=20):\n",
    "        '''\n",
    "        data: the feature matrix for the digit under consideration\n",
    "        prior: the prior probability of this digit\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        self.prior = prior\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D))  # number of features to consider for each split decision\n",
    "\n",
    "        # find and remember the tree's bounding box, \n",
    "        # i.e. the lower and upper limits of the training feature set\n",
    "        m, M = calc_bbox(data)\n",
    "        self.box = m, M\n",
    "\n",
    "        # identify invalid features and adjust the bounding box\n",
    "        # (If m[j] == M[j] for some j, the bounding box has zero volume, \n",
    "        #  causing divide-by-zero errors later on. We must exclude these\n",
    "        #  features from splitting and adjust the bounding box limits \n",
    "        #  such that invalid features have no effect on the volume.)\n",
    "        valid_features = np.where(m != M)[0]\n",
    "        invalid_features = np.where(m == M)[0]\n",
    "        M[invalid_features] = m[invalid_features] + 1\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.box = m.copy(), M.copy()\n",
    "\n",
    "        # build the tree\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0]  # number of instances in present node\n",
    "            if n >= n_min:\n",
    "                # Call 'make_density_split_node()' with 'D_try' randomly selected \n",
    "                # indices from 'valid_features'. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                indices = np.random.choice(np.arange(0, len(valid_features)), D_try, False)\n",
    "                left, right = make_density_split_node(node, N, valid_features[indices])\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "            else:\n",
    "                # Call 'make_density_leaf_node()' to turn 'node' into a leaf node.\n",
    "                make_density_leaf_node(node, N)\n",
    "\n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # return p(x | y) * p(y) if x is within the tree's bounding box \n",
    "        # and return 0 otherwise\n",
    "\n",
    "        if np.sum(x < self.box[0]) > 0 or np.sum(x > self.box[1]) > 0:\n",
    "            return 0.0\n",
    "        return self.prior * leaf.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loo_error(N_m: int, N: int, V_m: float) -> float:\n",
    "    # print()\n",
    "    # print(f'N_m = {N_m}')\n",
    "    # print(f'N = {N}')\n",
    "    # print(f'V_m = {V_m}')\n",
    "    # print(f'-(2 * N_m * (N_m - 1)) = {-(2 * N_m * (N_m - 1))}')\n",
    "    # print(f'(N * (N - 1) * V_m) = {(N * (N - 1) * V_m)}')\n",
    "    # print(f'(N_m ** 2) = {(N_m ** 2)}')\n",
    "    # print(f'((N ** 2) * V_m) = {((N ** 2) * V_m)}')\n",
    "    # print(f'-(2 * N_m * (N_m - 1)) / (N * (N - 1) * V_m) = {-(2 * N_m * (N_m - 1)) / (N * (N - 1) * V_m)}')\n",
    "    # print(f'(N_m ** 2) / ((N ** 2) * V_m) = {(N_m ** 2) / ((N ** 2) * V_m)}')\n",
    "    # print()\n",
    "    return -(2 * N_m * (N_m - 1)) / (N * (N - 1) * V_m) + (N_m ** 2) / ((N ** 2) * V_m)\n",
    "\n",
    "\n",
    "def calc_volume(bounding_box: Tuple[np.ndarray, np.ndarray]):\n",
    "    m, M = bounding_box\n",
    "    return np.prod(M - m)\n",
    "\n",
    "\n",
    "def make_density_split_node(node, N, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    N:    the total number of training instances for the current class\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "    m, M = node.box\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    e_min = float(\"inf\")\n",
    "    j_min, t_min = 0, 0\n",
    "\n",
    "    volume = calc_volume((m, M))\n",
    "\n",
    "    for j in feature_indices:\n",
    "        # Hint: For each feature considered, first remove duplicate feature values using\n",
    "        # 'np.unique()'. Describe here why this is necessary.\n",
    "\n",
    "        # It's necessary because otherwise if two instances have the same feature value the mean between them is the feature value self so the threshold would not be in the mid between feature values anymore\n",
    "\n",
    "        # np.unique returns an already sorted array\n",
    "        data_unique = np.unique(node.data[:, j])\n",
    "        # Compute candidate thresholds\n",
    "        tj = 0.5 * (data_unique[1:] + data_unique[:-1])\n",
    "\n",
    "        # Illustration: for loop - hint: vectorized version is possible\n",
    "        for t in tj:\n",
    "            # Compute the error\n",
    "            N_l = np.sum(node.data[:, j] <= t)\n",
    "            N_r = n - N_l\n",
    "\n",
    "            l_volume = volume * t / (M[j] - m[j])\n",
    "            r_volume = volume - l_volume\n",
    "\n",
    "            if l_volume != 0 and r_volume != 0:\n",
    "                loo_err_l = calc_loo_error(N_l, N, l_volume)\n",
    "                loo_err_r = calc_loo_error(N_r, N, r_volume)\n",
    "\n",
    "                loo_error = loo_err_l + loo_err_r\n",
    "\n",
    "                # print(f'loo_error: {loo_error}')\n",
    "\n",
    "                # choose the best threshold that\n",
    "                if loo_error < e_min:\n",
    "                    # print(f'e_min: {e_min}, j_min: {j_min}, t_min: {t_min}')\n",
    "                    e_min = loo_error\n",
    "                    j_min = j\n",
    "                    t_min = t\n",
    "\n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "\n",
    "    # initialize 'left' and 'right' with the data subsets and bounding boxes\n",
    "    # according to the optimal split found above\n",
    "    left.data = node.data[node.data[:, j_min] <= t_min, :]  # store data in left node -- for subsequent splits\n",
    "    left.box = m.copy(), M.copy()  # store bounding box in left node\n",
    "    left.box[1][j_min] = t_min\n",
    "    right.data = node.data[node.data[:, j_min] > t_min, :]\n",
    "    right.box = m.copy(), M.copy()\n",
    "    right.box[0][j_min] = t_min\n",
    "\n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = j_min\n",
    "    node.threshold = t_min\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_density_leaf_node(node, N):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    N:    the total number of training instances for the current class\n",
    "    '''\n",
    "    # compute and store leaf response\n",
    "    n = node.data.shape[0]\n",
    "    v = calc_volume(node.box)\n",
    "    node.response = n / (N * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DecisionTree, self).__init__()\n",
    "\n",
    "    def train(self, data, labels, n_min=20):\n",
    "        '''\n",
    "        data: the feature matrix for all digits\n",
    "        labels: the corresponding ground-truth responses\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D))  # how many features to consider for each split decision\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.labels = labels\n",
    "\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0]  # number of instances in present node\n",
    "            if n >= n_min and not node_is_pure(node):\n",
    "                # Call 'make_decision_split_node()' with 'D_try' randomly selected \n",
    "                # feature indices. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                indices = np.random.choice(np.arange(0, D), D_try, False)\n",
    "                left, right = make_decision_split_node(node, indices)\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "            else:\n",
    "                # Call 'make_decision_leaf_node()' to turn 'node' into a leaf node.\n",
    "                make_decision_leaf_node(node)\n",
    "\n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # compute p(y | x)\n",
    "        return np.argmax(leaf.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_gini(N_l_k: np.ndarray, N_l: int) -> float:\n",
    "    return N_l * (1 - np.sum((N_l_k / N_l) ** 2))\n",
    "\n",
    "\n",
    "def calc_N_l_k(node_target: np.ndarray, tresholded_indices: np.ndarray) -> np.ndarray:\n",
    "    return np.bincount(node_target[tresholded_indices], minlength=10)\n",
    "\n",
    "\n",
    "def make_decision_split_node(node, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "\n",
    "    e_min = float('inf')\n",
    "    t_min, j_min = 0, 0\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    for j in feature_indices:\n",
    "        data_unique = np.unique(node.data[:, j])\n",
    "        tj = 0.5 * (data_unique[1:] + data_unique[:-1])\n",
    "\n",
    "        if len(data_unique) > 1:\n",
    "            for t in tj:\n",
    "                indices_l = np.where(node.data[:, j] <= t)\n",
    "                indices_r = np.where(node.data[:, j] > t)\n",
    "\n",
    "                N_l_k_l = calc_N_l_k(node.labels, indices_l)\n",
    "                N_l_k_r = calc_N_l_k(node.labels, indices_r)\n",
    "\n",
    "                N_l_l = len(indices_l)\n",
    "                N_l_r = len(indices_r)\n",
    "\n",
    "                gini_l = calc_gini(N_l_k_l, N_l_l)\n",
    "                gini_r = calc_gini(N_l_k_r, N_l_r)\n",
    "\n",
    "                gini = gini_l + gini_r\n",
    "\n",
    "                if gini < e_min:\n",
    "                    e_min = gini\n",
    "                    t_min = t\n",
    "                    j_min = j\n",
    "\n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "\n",
    "    # initialize 'left' and 'right' with the data subsets and labels\n",
    "    # according to the optimal split found above\n",
    "    indices_l = np.where(node.data[:, j_min] <= t_min)\n",
    "    indices_r = np.where(node.data[:, j_min] > t_min)\n",
    "\n",
    "    left.data = node.data[indices_l]  # data in left node\n",
    "    left.labels = node.labels[indices_l]  # corresponding labels\n",
    "    right.data = node.data[indices_r]\n",
    "    right.labels = node.labels[indices_r]\n",
    "\n",
    "    # if len(left.data) == 0 or len(right.data) == 0:\n",
    "    #     print('Data empty')\n",
    "\n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = j_min\n",
    "    node.threshold = t_min\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_decision_leaf_node(node):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    '''\n",
    "    # compute and store leaf response\n",
    "    node.N = len(node.labels)\n",
    "    node.response = np.bincount(node.labels, minlength=10) / node.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def node_is_pure(node):\n",
    "    '''\n",
    "    check if 'node' ontains only instances of the same digit\n",
    "    '''\n",
    "    return len(np.unique(node.labels)) <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Density and Decision Tree\n",
    "Below we first load the dataset and reduce the dimensions to the dimensions with actual information in it (deleting the features with variance 0, because if every datapoint has the same value in one feature, the feature does not carry any information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50\n",
      " 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "(1797, 61)\n"
     ]
    }
   ],
   "source": [
    "# read and prepare the digits data\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]\n",
    "\n",
    "# Removing features where min value == max value == 0, because this feature does not contain any information (it's the same for all instances)\n",
    "smallest, biggest = calc_bbox(data)\n",
    "distances = biggest - smallest\n",
    "print(distances.shape)\n",
    "\n",
    "dims_with_information = np.where(distances > 0)[0]\n",
    "print(dims_with_information)\n",
    "\n",
    "data = data[:, dims_with_information]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afterwards we define a function to calculate the confusion matrix from  $\\hat{y}$ and $y*$ by comparing the expected y's per class with the calculated y's then bin counting that for each column in the confusion matrix."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train trees, plot training error confusion matrices, and comment on your results\n",
    "\n",
    "def calc_confusion_matrix(calculated_target, expected) -> pd.DataFrame:\n",
    "    matrix = np.zeros((10, 10))\n",
    "    matrix_dict = {}\n",
    "    for expected_num in range(10):\n",
    "        expected_indices = np.where(expected == expected_num)[0]\n",
    "        calculated_values = calculated_target[expected_indices]\n",
    "        calc_bins = np.bincount(calculated_values, minlength=10)\n",
    "        matrix[expected_num] = calc_bins / len(expected_indices)\n",
    "        matrix_dict[expected_num] = calc_bins / len(expected_indices)\n",
    "\n",
    "    data_frame = pd.DataFrame(matrix_dict)\n",
    "    data_frame.columns.name = 'actual/expected'\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we define a function that plots us the error per n_min for the different classifiers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def show_plot(errors: np.ndarray, n_mins: np.ndarray):\n",
    "    x = range(len(n_mins))\n",
    "    x_ticks = np.arange(len(n_mins))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x, errors)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(n_mins)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we create a one function for training and testing the generative classifier and one for the discriminative classifier.\n",
    "For training and testing the generative classifier, we first train each of the classifiers independently for exactly one class. Therefore we filter our test data for this class and then pass the filtered data and the calculated prior to the train function of the classifier.\n",
    "Afterwards we test by calculating the probability for each data point per classifier the classifier with the highest probability wins and determines which class the datapoint belongs to. With the results we then calculate the error and the confusion matrix.\n",
    "\n",
    "For the discriminative classifier we only have one instance which returns the class with the highest probability. We train the classifier with the data, predict afterwards each class per datapoint and then generate the confusion matrix and error rate out of it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def train_test_generative_classifier(generative_classifiers, n_min) -> float:\n",
    "    assert len(generative_classifiers) == 10\n",
    "    for number, density_tree in enumerate(generative_classifiers):\n",
    "        indices = np.where(target == number)\n",
    "        filtered_data = data[indices]\n",
    "        prior = len(filtered_data) / len(data)\n",
    "\n",
    "        density_tree.train(filtered_data, prior, n_min)\n",
    "\n",
    "    calculated_target = np.zeros(len(target), dtype=int)\n",
    "\n",
    "    for i, instance in enumerate(data):\n",
    "        p_max = -1\n",
    "        num_max = -1\n",
    "        for number, tree in enumerate(generative_classifiers):\n",
    "            p = tree.predict(instance)\n",
    "            if p > p_max:\n",
    "                p_max = p\n",
    "                num_max = number\n",
    "        calculated_target[i] = num_max\n",
    "\n",
    "    # print(target)\n",
    "    # print(calculated_target)\n",
    "    density_tree_err = calculated_target != target\n",
    "    # print(density_tree_err)\n",
    "\n",
    "    density_tree_err_rate = np.sum(density_tree_err) / len(target)\n",
    "    confusion_matrix = calc_confusion_matrix(calculated_target, target)\n",
    "    print(f'Error rate: {density_tree_err_rate}')\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix)\n",
    "\n",
    "    return density_tree_err_rate\n",
    "\n",
    "\n",
    "def train_test_discriminative_classifier(discriminative_classifier, n_min) -> float:\n",
    "    discriminative_classifier.train(data, target, n_min)\n",
    "\n",
    "    calculated_target = np.array([discriminative_classifier.predict(instance) for instance in data], dtype=int)\n",
    "\n",
    "    decision_tree_err = calculated_target != target\n",
    "    # print(decision_tree_err)\n",
    "\n",
    "    decision_tree_err_rate = np.sum(decision_tree_err) / len(target)\n",
    "    confusion_matrix = calc_confusion_matrix(calculated_target, target)\n",
    "    print(f'Error rate: {decision_tree_err_rate}')\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix)\n",
    "\n",
    "    return decision_tree_err_rate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The actual execution of the train and test methods from above is done in the train_test methods which accepts as first two parameters factory methods for creating new generative and discriminative classifiers. This is used for reusing the function for the forests.\n",
    "The two second parameters are arrays of n_min values for the two different classifier types which shall be trained and tested.\n",
    "The function itself just iterates ovet the n_mins for both the generative and discriminative classifiers and execute their respective train and test function from above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative classifier:\n",
      "n_min: 20\n",
      "Error rate: 0.2036727879799666\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.983146  0.000000  0.000000  0.000000  0.000000  0.000000   \n1                0.000000  0.785714  0.112994  0.032787  0.016575  0.027473   \n2                0.000000  0.076923  0.677966  0.038251  0.000000  0.005495   \n3                0.000000  0.000000  0.022599  0.633880  0.000000  0.104396   \n4                0.016854  0.049451  0.000000  0.000000  0.850829  0.000000   \n5                0.000000  0.000000  0.022599  0.016393  0.011050  0.708791   \n6                0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n7                0.000000  0.005495  0.000000  0.016393  0.116022  0.065934   \n8                0.000000  0.082418  0.163842  0.256831  0.005525  0.082418   \n9                0.000000  0.000000  0.000000  0.005464  0.000000  0.005495   \n\nactual/expected        6         7         8         9  \n0                0.00000  0.000000  0.000000  0.000000  \n1                0.01105  0.000000  0.120690  0.022222  \n2                0.00000  0.000000  0.011494  0.011111  \n3                0.00000  0.005587  0.005747  0.200000  \n4                0.00000  0.011173  0.005747  0.033333  \n5                0.00000  0.000000  0.011494  0.016667  \n6                0.98895  0.000000  0.000000  0.000000  \n7                0.00000  0.977654  0.011494  0.066667  \n8                0.00000  0.005587  0.833333  0.122222  \n9                0.00000  0.000000  0.000000  0.527778  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.983146</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.785714</td>\n      <td>0.112994</td>\n      <td>0.032787</td>\n      <td>0.016575</td>\n      <td>0.027473</td>\n      <td>0.01105</td>\n      <td>0.000000</td>\n      <td>0.120690</td>\n      <td>0.022222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.076923</td>\n      <td>0.677966</td>\n      <td>0.038251</td>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.011494</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.022599</td>\n      <td>0.633880</td>\n      <td>0.000000</td>\n      <td>0.104396</td>\n      <td>0.00000</td>\n      <td>0.005587</td>\n      <td>0.005747</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.016854</td>\n      <td>0.049451</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.850829</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.011173</td>\n      <td>0.005747</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.022599</td>\n      <td>0.016393</td>\n      <td>0.011050</td>\n      <td>0.708791</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.011494</td>\n      <td>0.016667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.98895</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.016393</td>\n      <td>0.116022</td>\n      <td>0.065934</td>\n      <td>0.00000</td>\n      <td>0.977654</td>\n      <td>0.011494</td>\n      <td>0.066667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.000000</td>\n      <td>0.082418</td>\n      <td>0.163842</td>\n      <td>0.256831</td>\n      <td>0.005525</td>\n      <td>0.082418</td>\n      <td>0.00000</td>\n      <td>0.005587</td>\n      <td>0.833333</td>\n      <td>0.122222</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005464</td>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.527778</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_min: 10\n",
      "Error rate: 0.19810795770728992\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected    0         1         2         3         4         5  \\\n0                1.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n1                0.0  0.725275  0.016949  0.000000  0.011050  0.000000   \n2                0.0  0.043956  0.570621  0.027322  0.000000  0.000000   \n3                0.0  0.000000  0.050847  0.546448  0.000000  0.021978   \n4                0.0  0.032967  0.000000  0.000000  0.834254  0.005495   \n5                0.0  0.005495  0.000000  0.038251  0.016575  0.802198   \n6                0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n7                0.0  0.027473  0.000000  0.016393  0.110497  0.032967   \n8                0.0  0.131868  0.350282  0.158470  0.005525  0.098901   \n9                0.0  0.032967  0.011299  0.213115  0.022099  0.038462   \n\nactual/expected         6         7         8         9  \n0                0.000000  0.000000  0.000000  0.000000  \n1                0.005525  0.000000  0.034483  0.011111  \n2                0.000000  0.000000  0.017241  0.011111  \n3                0.000000  0.000000  0.000000  0.094444  \n4                0.000000  0.005587  0.000000  0.027778  \n5                0.000000  0.005587  0.000000  0.033333  \n6                0.994475  0.000000  0.000000  0.000000  \n7                0.000000  0.977654  0.022989  0.055556  \n8                0.000000  0.000000  0.890805  0.083333  \n9                0.000000  0.011173  0.034483  0.683333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.725275</td>\n      <td>0.016949</td>\n      <td>0.000000</td>\n      <td>0.011050</td>\n      <td>0.000000</td>\n      <td>0.005525</td>\n      <td>0.000000</td>\n      <td>0.034483</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.043956</td>\n      <td>0.570621</td>\n      <td>0.027322</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.017241</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.050847</td>\n      <td>0.546448</td>\n      <td>0.000000</td>\n      <td>0.021978</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.094444</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.032967</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.834254</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.038251</td>\n      <td>0.016575</td>\n      <td>0.802198</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.000000</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.994475</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.027473</td>\n      <td>0.000000</td>\n      <td>0.016393</td>\n      <td>0.110497</td>\n      <td>0.032967</td>\n      <td>0.000000</td>\n      <td>0.977654</td>\n      <td>0.022989</td>\n      <td>0.055556</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.131868</td>\n      <td>0.350282</td>\n      <td>0.158470</td>\n      <td>0.005525</td>\n      <td>0.098901</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.890805</td>\n      <td>0.083333</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.032967</td>\n      <td>0.011299</td>\n      <td>0.213115</td>\n      <td>0.022099</td>\n      <td>0.038462</td>\n      <td>0.000000</td>\n      <td>0.011173</td>\n      <td>0.034483</td>\n      <td>0.683333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_min: 5\n",
      "Error rate: 0.15859766277128548\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.994382  0.000000  0.000000  0.000000  0.000000  0.000000   \n1                0.000000  0.769231  0.039548  0.005464  0.011050  0.005495   \n2                0.000000  0.093407  0.847458  0.114754  0.000000  0.005495   \n3                0.000000  0.000000  0.016949  0.732240  0.000000  0.093407   \n4                0.005618  0.021978  0.000000  0.000000  0.939227  0.005495   \n5                0.000000  0.010989  0.000000  0.000000  0.000000  0.813187   \n6                0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n7                0.000000  0.027473  0.000000  0.010929  0.044199  0.027473   \n8                0.000000  0.076923  0.096045  0.109290  0.005525  0.043956   \n9                0.000000  0.000000  0.000000  0.027322  0.000000  0.005495   \n\nactual/expected         6         7         8         9  \n0                0.000000  0.000000  0.000000  0.000000  \n1                0.000000  0.000000  0.040230  0.016667  \n2                0.005525  0.000000  0.097701  0.016667  \n3                0.000000  0.000000  0.011494  0.233333  \n4                0.000000  0.011173  0.005747  0.033333  \n5                0.005525  0.000000  0.011494  0.005556  \n6                0.988950  0.000000  0.000000  0.000000  \n7                0.000000  0.983240  0.040230  0.044444  \n8                0.000000  0.000000  0.793103  0.094444  \n9                0.000000  0.005587  0.000000  0.555556  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.994382</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.769231</td>\n      <td>0.039548</td>\n      <td>0.005464</td>\n      <td>0.011050</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.040230</td>\n      <td>0.016667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.093407</td>\n      <td>0.847458</td>\n      <td>0.114754</td>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.005525</td>\n      <td>0.000000</td>\n      <td>0.097701</td>\n      <td>0.016667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016949</td>\n      <td>0.732240</td>\n      <td>0.000000</td>\n      <td>0.093407</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011494</td>\n      <td>0.233333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005618</td>\n      <td>0.021978</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.939227</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.011173</td>\n      <td>0.005747</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.010989</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.813187</td>\n      <td>0.005525</td>\n      <td>0.000000</td>\n      <td>0.011494</td>\n      <td>0.005556</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.988950</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.027473</td>\n      <td>0.000000</td>\n      <td>0.010929</td>\n      <td>0.044199</td>\n      <td>0.027473</td>\n      <td>0.000000</td>\n      <td>0.983240</td>\n      <td>0.040230</td>\n      <td>0.044444</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.000000</td>\n      <td>0.076923</td>\n      <td>0.096045</td>\n      <td>0.109290</td>\n      <td>0.005525</td>\n      <td>0.043956</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.793103</td>\n      <td>0.094444</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.027322</td>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.000000</td>\n      <td>0.555556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discriminative classifier:\n",
      "n_min: 20\n",
      "Error rate: 0.31886477462437396\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.814607  0.000000  0.016949  0.005464  0.016575  0.000000   \n1                0.005618  0.884615  0.050847  0.010929  0.060773  0.032967   \n2                0.011236  0.000000  0.598870  0.054645  0.005525  0.027473   \n3                0.005618  0.027473  0.090395  0.633880  0.005525  0.126374   \n4                0.011236  0.000000  0.011299  0.010929  0.762431  0.038462   \n5                0.005618  0.010989  0.135593  0.109290  0.011050  0.648352   \n6                0.022472  0.038462  0.045198  0.098361  0.022099  0.027473   \n7                0.056180  0.010989  0.000000  0.032787  0.088398  0.060440   \n8                0.028090  0.005495  0.033898  0.027322  0.016575  0.010989   \n9                0.039326  0.021978  0.016949  0.016393  0.011050  0.027473   \n\nactual/expected         6         7         8         9  \n0                0.005525  0.022346  0.028736  0.038889  \n1                0.022099  0.027933  0.109195  0.061111  \n2                0.011050  0.000000  0.097701  0.077778  \n3                0.016575  0.022346  0.103448  0.111111  \n4                0.005525  0.100559  0.000000  0.027778  \n5                0.011050  0.050279  0.086207  0.066667  \n6                0.906077  0.005587  0.091954  0.094444  \n7                0.000000  0.731844  0.017241  0.066667  \n8                0.005525  0.000000  0.425287  0.061111  \n9                0.016575  0.039106  0.040230  0.394444  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.814607</td>\n      <td>0.000000</td>\n      <td>0.016949</td>\n      <td>0.005464</td>\n      <td>0.016575</td>\n      <td>0.000000</td>\n      <td>0.005525</td>\n      <td>0.022346</td>\n      <td>0.028736</td>\n      <td>0.038889</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.005618</td>\n      <td>0.884615</td>\n      <td>0.050847</td>\n      <td>0.010929</td>\n      <td>0.060773</td>\n      <td>0.032967</td>\n      <td>0.022099</td>\n      <td>0.027933</td>\n      <td>0.109195</td>\n      <td>0.061111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.011236</td>\n      <td>0.000000</td>\n      <td>0.598870</td>\n      <td>0.054645</td>\n      <td>0.005525</td>\n      <td>0.027473</td>\n      <td>0.011050</td>\n      <td>0.000000</td>\n      <td>0.097701</td>\n      <td>0.077778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.005618</td>\n      <td>0.027473</td>\n      <td>0.090395</td>\n      <td>0.633880</td>\n      <td>0.005525</td>\n      <td>0.126374</td>\n      <td>0.016575</td>\n      <td>0.022346</td>\n      <td>0.103448</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.011236</td>\n      <td>0.000000</td>\n      <td>0.011299</td>\n      <td>0.010929</td>\n      <td>0.762431</td>\n      <td>0.038462</td>\n      <td>0.005525</td>\n      <td>0.100559</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.005618</td>\n      <td>0.010989</td>\n      <td>0.135593</td>\n      <td>0.109290</td>\n      <td>0.011050</td>\n      <td>0.648352</td>\n      <td>0.011050</td>\n      <td>0.050279</td>\n      <td>0.086207</td>\n      <td>0.066667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.022472</td>\n      <td>0.038462</td>\n      <td>0.045198</td>\n      <td>0.098361</td>\n      <td>0.022099</td>\n      <td>0.027473</td>\n      <td>0.906077</td>\n      <td>0.005587</td>\n      <td>0.091954</td>\n      <td>0.094444</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.056180</td>\n      <td>0.010989</td>\n      <td>0.000000</td>\n      <td>0.032787</td>\n      <td>0.088398</td>\n      <td>0.060440</td>\n      <td>0.000000</td>\n      <td>0.731844</td>\n      <td>0.017241</td>\n      <td>0.066667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.028090</td>\n      <td>0.005495</td>\n      <td>0.033898</td>\n      <td>0.027322</td>\n      <td>0.016575</td>\n      <td>0.010989</td>\n      <td>0.005525</td>\n      <td>0.000000</td>\n      <td>0.425287</td>\n      <td>0.061111</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.039326</td>\n      <td>0.021978</td>\n      <td>0.016949</td>\n      <td>0.016393</td>\n      <td>0.011050</td>\n      <td>0.027473</td>\n      <td>0.016575</td>\n      <td>0.039106</td>\n      <td>0.040230</td>\n      <td>0.394444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_min: 10\n",
      "Error rate: 0.19365609348914858\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.966292  0.000000  0.000000  0.005464  0.016575  0.005495   \n1                0.000000  0.917582  0.056497  0.027322  0.005525  0.038462   \n2                0.000000  0.027473  0.768362  0.071038  0.016575  0.016484   \n3                0.005618  0.005495  0.056497  0.721311  0.005525  0.005495   \n4                0.016854  0.010989  0.016949  0.010929  0.895028  0.016484   \n5                0.000000  0.000000  0.045198  0.016393  0.016575  0.884615   \n6                0.005618  0.000000  0.011299  0.016393  0.000000  0.000000   \n7                0.000000  0.016484  0.000000  0.010929  0.027624  0.021978   \n8                0.005618  0.010989  0.016949  0.032787  0.005525  0.005495   \n9                0.000000  0.010989  0.028249  0.087432  0.011050  0.005495   \n\nactual/expected         6         7         8         9  \n0                0.000000  0.011173  0.017241  0.022222  \n1                0.011050  0.072626  0.097701  0.038889  \n2                0.000000  0.011173  0.097701  0.061111  \n3                0.044199  0.027933  0.091954  0.088889  \n4                0.000000  0.055866  0.017241  0.011111  \n5                0.000000  0.016760  0.022989  0.005556  \n6                0.944751  0.000000  0.000000  0.005556  \n7                0.000000  0.782123  0.028736  0.055556  \n8                0.000000  0.005587  0.534483  0.072222  \n9                0.000000  0.016760  0.091954  0.638889  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.966292</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005464</td>\n      <td>0.016575</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.011173</td>\n      <td>0.017241</td>\n      <td>0.022222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.917582</td>\n      <td>0.056497</td>\n      <td>0.027322</td>\n      <td>0.005525</td>\n      <td>0.038462</td>\n      <td>0.011050</td>\n      <td>0.072626</td>\n      <td>0.097701</td>\n      <td>0.038889</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.027473</td>\n      <td>0.768362</td>\n      <td>0.071038</td>\n      <td>0.016575</td>\n      <td>0.016484</td>\n      <td>0.000000</td>\n      <td>0.011173</td>\n      <td>0.097701</td>\n      <td>0.061111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.005618</td>\n      <td>0.005495</td>\n      <td>0.056497</td>\n      <td>0.721311</td>\n      <td>0.005525</td>\n      <td>0.005495</td>\n      <td>0.044199</td>\n      <td>0.027933</td>\n      <td>0.091954</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.016854</td>\n      <td>0.010989</td>\n      <td>0.016949</td>\n      <td>0.010929</td>\n      <td>0.895028</td>\n      <td>0.016484</td>\n      <td>0.000000</td>\n      <td>0.055866</td>\n      <td>0.017241</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.045198</td>\n      <td>0.016393</td>\n      <td>0.016575</td>\n      <td>0.884615</td>\n      <td>0.000000</td>\n      <td>0.016760</td>\n      <td>0.022989</td>\n      <td>0.005556</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.005618</td>\n      <td>0.000000</td>\n      <td>0.011299</td>\n      <td>0.016393</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.944751</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005556</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.016484</td>\n      <td>0.000000</td>\n      <td>0.010929</td>\n      <td>0.027624</td>\n      <td>0.021978</td>\n      <td>0.000000</td>\n      <td>0.782123</td>\n      <td>0.028736</td>\n      <td>0.055556</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.005618</td>\n      <td>0.010989</td>\n      <td>0.016949</td>\n      <td>0.032787</td>\n      <td>0.005525</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.534483</td>\n      <td>0.072222</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.010989</td>\n      <td>0.028249</td>\n      <td>0.087432</td>\n      <td>0.011050</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.016760</td>\n      <td>0.091954</td>\n      <td>0.638889</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_min: 5\n",
      "Error rate: 0.10962715637173066\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.971910  0.000000  0.000000  0.005464  0.000000  0.000000   \n1                0.000000  0.939560  0.039548  0.010929  0.011050  0.016484   \n2                0.000000  0.000000  0.892655  0.065574  0.027624  0.043956   \n3                0.005618  0.010989  0.028249  0.846995  0.005525  0.043956   \n4                0.011236  0.000000  0.000000  0.005464  0.950276  0.016484   \n5                0.005618  0.000000  0.005650  0.010929  0.000000  0.873626   \n6                0.005618  0.010989  0.000000  0.021858  0.005525  0.005495   \n7                0.000000  0.000000  0.000000  0.016393  0.000000  0.000000   \n8                0.000000  0.032967  0.033898  0.005464  0.000000  0.000000   \n9                0.000000  0.005495  0.000000  0.010929  0.000000  0.000000   \n\nactual/expected         6         7         8         9  \n0                0.000000  0.000000  0.000000  0.016667  \n1                0.000000  0.022346  0.051724  0.005556  \n2                0.033149  0.000000  0.068966  0.011111  \n3                0.011050  0.005587  0.074713  0.038889  \n4                0.005525  0.039106  0.011494  0.005556  \n5                0.016575  0.022346  0.017241  0.027778  \n6                0.922652  0.000000  0.011494  0.011111  \n7                0.000000  0.893855  0.000000  0.011111  \n8                0.011050  0.005587  0.752874  0.016667  \n9                0.000000  0.011173  0.011494  0.855556  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.971910</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005464</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.939560</td>\n      <td>0.039548</td>\n      <td>0.010929</td>\n      <td>0.011050</td>\n      <td>0.016484</td>\n      <td>0.000000</td>\n      <td>0.022346</td>\n      <td>0.051724</td>\n      <td>0.005556</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.892655</td>\n      <td>0.065574</td>\n      <td>0.027624</td>\n      <td>0.043956</td>\n      <td>0.033149</td>\n      <td>0.000000</td>\n      <td>0.068966</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.005618</td>\n      <td>0.010989</td>\n      <td>0.028249</td>\n      <td>0.846995</td>\n      <td>0.005525</td>\n      <td>0.043956</td>\n      <td>0.011050</td>\n      <td>0.005587</td>\n      <td>0.074713</td>\n      <td>0.038889</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.011236</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005464</td>\n      <td>0.950276</td>\n      <td>0.016484</td>\n      <td>0.005525</td>\n      <td>0.039106</td>\n      <td>0.011494</td>\n      <td>0.005556</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.005618</td>\n      <td>0.000000</td>\n      <td>0.005650</td>\n      <td>0.010929</td>\n      <td>0.000000</td>\n      <td>0.873626</td>\n      <td>0.016575</td>\n      <td>0.022346</td>\n      <td>0.017241</td>\n      <td>0.027778</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.005618</td>\n      <td>0.010989</td>\n      <td>0.000000</td>\n      <td>0.021858</td>\n      <td>0.005525</td>\n      <td>0.005495</td>\n      <td>0.922652</td>\n      <td>0.000000</td>\n      <td>0.011494</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016393</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.893855</td>\n      <td>0.000000</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.000000</td>\n      <td>0.032967</td>\n      <td>0.033898</td>\n      <td>0.005464</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011050</td>\n      <td>0.005587</td>\n      <td>0.752874</td>\n      <td>0.016667</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.010929</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011173</td>\n      <td>0.011494</td>\n      <td>0.855556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_min: 0\n",
      "Error rate: 0.0\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected    0    1    2    3    4    5    6    7    8    9\n0                1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n1                0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n2                0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n3                0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n4                0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n5                0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n6                0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n7                0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n8                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n9                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_test(create_generative_classifiers, create_discriminative_classifier, generative_n_mins,\n",
    "               discriminative_n_mins):\n",
    "    density_tree_error = []\n",
    "    print('Generative classifier:')\n",
    "    for hyper_n_min in generative_n_mins:\n",
    "        print(f'n_min: {hyper_n_min}')\n",
    "        density_trees = create_generative_classifiers()\n",
    "        error = train_test_generative_classifier(density_trees, hyper_n_min)\n",
    "        density_tree_error.append(error)\n",
    "    show_plot(density_tree_error, generative_n_mins)\n",
    "\n",
    "    decision_tree_error = []\n",
    "    print()\n",
    "    print('Discriminative classifier:')\n",
    "    for hyper_n_min in discriminative_n_mins:\n",
    "        print(f'n_min: {hyper_n_min}')\n",
    "        error = train_test_discriminative_classifier(create_discriminative_classifier(), hyper_n_min)\n",
    "        decision_tree_error.append(error)\n",
    "    show_plot(decision_tree_error, discriminative_n_mins)\n",
    "\n",
    "\n",
    "train_test(lambda: [DensityTree() for _ in range(10)], lambda: DecisionTree(), [20, 10, 5], [20, 10, 5, 0])\n",
    "\n",
    "#train_test(lambda: [], lambda: DecisionTree(), [], [0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a result the discriminative classifier (decision tree) performs a lot better than the density tree. For decreasing n_mins the error rate also decreases for both classifiers.\n",
    "With n_min = 0 for the decision tree performs a perfect fit on the train data, this means every node is pure and therefore every datapoint from the training set will be categorized correctly. Unfortunately this might also be overfitting and test data might perform in another way.\n",
    "\n",
    "The confusion matrix can be read as following: The diagonal is the share of correctly classified numbers ranging from zero to one. The other values in the matrix are the respective share of  the wrongly categorized values. e.g. for the generative classifier with n_min = 20 the share of wrongly classified 2 when expecting a 1 is 0.076923."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density and Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DensityForest():\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [DensityTree() for i in range(n_trees)]\n",
    "\n",
    "    def train(self, data, prior, n_min=20):\n",
    "        for tree in self.trees:\n",
    "            # train each tree, using a bootstrap sample of the data\n",
    "\n",
    "            train_indices = np.random.choice(np.arange(len(data)), len(data), True)\n",
    "            train_data = data[train_indices]\n",
    "            tree.train(train_data, prior, n_min)\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return np.sum(np.array([tree.predict(x) for tree in self.trees])) / len(self.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DecisionForest():\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [DecisionTree() for i in range(n_trees)]\n",
    "\n",
    "    def train(self, data, labels, n_min=0):\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            # train each tree, using a bootstrap sample of the da\n",
    "            # print(f'Training decision tree {i}')\n",
    "            train_indices = np.random.choice(range(len(data)), len(data), True)\n",
    "            train_data = data[train_indices]\n",
    "            train_labels = labels[train_indices]\n",
    "            tree.train(train_data, train_labels, n_min)\n",
    "            # print(f'Decision tree {i} trained')\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return np.argmax(np.bincount([tree.predict(x) for tree in self.trees], minlength=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Density and Decision Forest\n",
    "For the forest algorithms we reuse the evaluation functions from above and just pass a function that generates an array with 10 `DensityForest`s and a function which creates a new `DecisionForest`, As hyperparameters we choose n_min = 20 for the generative classifier (density forest) and n_min = 0 for the decision forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative classifier:\n",
      "n_min: 20\n",
      "Error rate: 0.10072342793544797\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.994382  0.000000  0.000000  0.000000  0.000000  0.000000   \n1                0.005618  0.945055  0.056497  0.005464  0.011050  0.000000   \n2                0.000000  0.016484  0.853107  0.000000  0.000000  0.000000   \n3                0.000000  0.000000  0.033898  0.836066  0.000000  0.049451   \n4                0.000000  0.005495  0.000000  0.000000  0.961326  0.005495   \n5                0.000000  0.005495  0.000000  0.010929  0.000000  0.879121   \n6                0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n7                0.000000  0.005495  0.000000  0.021858  0.027624  0.010989   \n8                0.000000  0.021978  0.056497  0.120219  0.000000  0.043956   \n9                0.000000  0.000000  0.000000  0.005464  0.000000  0.010989   \n\nactual/expected    6         7         8         9  \n0                0.0  0.000000  0.000000  0.000000  \n1                0.0  0.000000  0.074713  0.016667  \n2                0.0  0.000000  0.000000  0.000000  \n3                0.0  0.000000  0.005747  0.211111  \n4                0.0  0.000000  0.000000  0.011111  \n5                0.0  0.000000  0.005747  0.011111  \n6                1.0  0.000000  0.000000  0.000000  \n7                0.0  0.994413  0.000000  0.044444  \n8                0.0  0.005587  0.913793  0.088889  \n9                0.0  0.000000  0.000000  0.616667  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.994382</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.005618</td>\n      <td>0.945055</td>\n      <td>0.056497</td>\n      <td>0.005464</td>\n      <td>0.011050</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.074713</td>\n      <td>0.016667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.016484</td>\n      <td>0.853107</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033898</td>\n      <td>0.836066</td>\n      <td>0.000000</td>\n      <td>0.049451</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.005747</td>\n      <td>0.211111</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.961326</td>\n      <td>0.005495</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.010929</td>\n      <td>0.000000</td>\n      <td>0.879121</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.005747</td>\n      <td>0.011111</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.021858</td>\n      <td>0.027624</td>\n      <td>0.010989</td>\n      <td>0.0</td>\n      <td>0.994413</td>\n      <td>0.000000</td>\n      <td>0.044444</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.000000</td>\n      <td>0.021978</td>\n      <td>0.056497</td>\n      <td>0.120219</td>\n      <td>0.000000</td>\n      <td>0.043956</td>\n      <td>0.0</td>\n      <td>0.005587</td>\n      <td>0.913793</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005464</td>\n      <td>0.000000</td>\n      <td>0.010989</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.616667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discriminative classifier:\n",
      "n_min: 20\n",
      "Error rate: 0.12799109627156371\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected         0         1         2         3         4         5  \\\n0                0.977528  0.000000  0.000000  0.005464  0.022099  0.005495   \n1                0.000000  0.967033  0.039548  0.005464  0.011050  0.010989   \n2                0.000000  0.005495  0.875706  0.076503  0.000000  0.021978   \n3                0.005618  0.000000  0.039548  0.786885  0.000000  0.038462   \n4                0.005618  0.000000  0.005650  0.005464  0.922652  0.021978   \n5                0.000000  0.021978  0.011299  0.027322  0.016575  0.873626   \n6                0.005618  0.000000  0.011299  0.032787  0.000000  0.010989   \n7                0.000000  0.000000  0.011299  0.032787  0.027624  0.005495   \n8                0.005618  0.000000  0.005650  0.016393  0.000000  0.005495   \n9                0.000000  0.005495  0.000000  0.010929  0.000000  0.005495   \n\nactual/expected         6         7         8         9  \n0                0.000000  0.005587  0.005747  0.022222  \n1                0.016575  0.005587  0.022989  0.022222  \n2                0.000000  0.005587  0.063218  0.044444  \n3                0.011050  0.000000  0.040230  0.072222  \n4                0.005525  0.055866  0.011494  0.027778  \n5                0.000000  0.033520  0.051724  0.038889  \n6                0.966851  0.000000  0.017241  0.038889  \n7                0.000000  0.888268  0.000000  0.038889  \n8                0.000000  0.000000  0.787356  0.022222  \n9                0.000000  0.005587  0.000000  0.672222  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.977528</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005464</td>\n      <td>0.022099</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.005747</td>\n      <td>0.022222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.967033</td>\n      <td>0.039548</td>\n      <td>0.005464</td>\n      <td>0.011050</td>\n      <td>0.010989</td>\n      <td>0.016575</td>\n      <td>0.005587</td>\n      <td>0.022989</td>\n      <td>0.022222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.875706</td>\n      <td>0.076503</td>\n      <td>0.000000</td>\n      <td>0.021978</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.063218</td>\n      <td>0.044444</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.005618</td>\n      <td>0.000000</td>\n      <td>0.039548</td>\n      <td>0.786885</td>\n      <td>0.000000</td>\n      <td>0.038462</td>\n      <td>0.011050</td>\n      <td>0.000000</td>\n      <td>0.040230</td>\n      <td>0.072222</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005618</td>\n      <td>0.000000</td>\n      <td>0.005650</td>\n      <td>0.005464</td>\n      <td>0.922652</td>\n      <td>0.021978</td>\n      <td>0.005525</td>\n      <td>0.055866</td>\n      <td>0.011494</td>\n      <td>0.027778</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.021978</td>\n      <td>0.011299</td>\n      <td>0.027322</td>\n      <td>0.016575</td>\n      <td>0.873626</td>\n      <td>0.000000</td>\n      <td>0.033520</td>\n      <td>0.051724</td>\n      <td>0.038889</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.005618</td>\n      <td>0.000000</td>\n      <td>0.011299</td>\n      <td>0.032787</td>\n      <td>0.000000</td>\n      <td>0.010989</td>\n      <td>0.966851</td>\n      <td>0.000000</td>\n      <td>0.017241</td>\n      <td>0.038889</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011299</td>\n      <td>0.032787</td>\n      <td>0.027624</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.888268</td>\n      <td>0.000000</td>\n      <td>0.038889</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.005618</td>\n      <td>0.000000</td>\n      <td>0.005650</td>\n      <td>0.016393</td>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.787356</td>\n      <td>0.022222</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.010929</td>\n      <td>0.000000</td>\n      <td>0.005495</td>\n      <td>0.000000</td>\n      <td>0.005587</td>\n      <td>0.000000</td>\n      <td>0.672222</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_min: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145619/981153019.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  node.response = np.bincount(node.labels, minlength=10) / node.N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 0.0005564830272676684\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": "actual/expected    0    1    2    3    4    5    6    7    8         9\n0                1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.005556\n1                0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n2                0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n3                0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.000000\n4                0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.000000\n5                0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.000000\n6                0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.000000\n7                0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.000000\n8                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.000000\n9                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.994444",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>actual/expected</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.005556</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.994444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train forests (with 20 trees per forest), plot training error confusion matrices, and comment on your results\n",
    "train_test(lambda: [DensityForest(20) for _ in range(10)], lambda: DecisionForest(20), [20], [20, 0])\n",
    "\n",
    "sklearn_random_forest = RandomForestClassifier(20, min_samples_split = 20)\n",
    "sklearn_random_forest.fit(data,target)\n",
    "\n",
    "sklean_calculated = sklearn_random_forest.predict(data)\n",
    "\n",
    "sklearn_err = sklean_calculated != target\n",
    "sklearn_err_rate = np.sum(sklearn_err) / len(target)\n",
    "calc_confusion_matrix(sklean_calculated, target)\n",
    "show_plot(np.array([sklearn_err_rate]), np.array([0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference in the results between the generative and the discriminative classifier continue for the forest algorithms. the Decision forest performs a lot better then the density forest. The density forest has an error rate in the parts-per-thousands range where the density forest has an error from around 10%.\n",
    "The sklearn implementation of the random forest performs better for n_min= 20, but when setting n_min to 0 for the decision forest they perform quite similar\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}